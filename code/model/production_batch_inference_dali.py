#!/usr/bin/env python3
"""
Production Batch Inference with NVIDIA DALI GPU Decoding
- Replaces PyAV CPU decoding with DALI GPU pipeline
- Zero-copy GPU memory transfers
- Optimized for 1+ hour video files with maximum throughput
- Maintains compatibility with existing TensorRT clean engine
"""

import pandas as pd
from pathlib import Path
import os
import csv
# import torch  # No longer needed - using native GPU NMS
# import torchvision.ops as ops  # No longer needed - using native GPU NMS
import numpy as np
import tensorrt as trt
import pycuda.driver as cuda
import pycuda.autoinit
import time
import sys
import argparse
from datetime import datetime, timedelta

# NVIDIA DALI imports
try:
    import nvidia.dali as dali
    from nvidia.dali import pipeline_def
    import nvidia.dali.fn as fn
    from nvidia.dali.plugin.pytorch import DALIGenericIterator, LastBatchPolicy
    from nvidia.dali import types
    DALI_AVAILABLE = True
except ImportError:
    DALI_AVAILABLE = False
    print("‚ö†Ô∏è  NVIDIA DALI not available. Install with: pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda120")

TRT_LOGGER = trt.Logger(trt.Logger.WARNING)

@pipeline_def
def video_decode_pipeline(video_path, seq_length, frame_skip=1):
    """
    DALI pipeline for GPU-accelerated video decoding and preprocessing
    
    Args:
        video_path: Path to input video file
        seq_length: Number of frames per batch (sequence_length)
        frame_skip: Process every Nth frame (1 = all frames)
    
    Returns:
        Preprocessed frames ready for TensorRT: (batch_size, 3, 960, 960) float32
    """
    
    # GPU-based video decoding with robust frame handling
    video = fn.readers.video(
        device="gpu",
        file_root="",
        filenames=[video_path],
        sequence_length=seq_length,
        step=frame_skip,  # Skip frames for efficiency
        stride=1,         # Sequential frame reading
        normalized=False, # Keep as uint8 initially
        random_shuffle=False,
        pad_last_batch=True,
        skip_vfr_check=True,  # Allow variable frame rate videos
        enable_frame_num=False,  # Disable frame number tracking
        enable_timestamps=False,  # Disable timestamp tracking
        file_list_include_preceding_frame=True,  # Include preceding frame for better continuity
        dont_use_mmap=True,  # Force reading into memory instead of memory mapping
        name="video_reader"
    )
    
    # Resize to target resolution (960x960) on GPU
    resized = fn.resize(
        video,
        device="gpu",
        size=[960, 960],
        interp_type=types.INTERP_LINEAR,
        antialias=True
    )
    
    # Convert to float and normalize to [0,1] range on GPU
    normalized = fn.cast(resized, device="gpu", dtype=types.FLOAT)
    normalized = normalized / 255.0
    
    # Transpose from NHWC to NCHW format for TensorRT (4D: batch, h, w, c -> batch, c, h, w)
    transposed = fn.transpose(normalized, device="gpu", perm=[0, 3, 1, 2])
    
    return transposed

class DALIVideoProcessor:
    """DALI-based video processor for maximum GPU utilization"""
    
    def __init__(self, batch_size=8, device_id=0, frame_skip=25):
        self.batch_size = batch_size
        self.device_id = device_id
        self.frame_skip = frame_skip
        self.pipeline = None
        self.iterator = None
        
        if not DALI_AVAILABLE:
            raise RuntimeError("NVIDIA DALI is required for GPU decoding")
        
        print(f"üöÄ Initializing DALI GPU Video Processor")
        print(f"   Batch size: {batch_size}")
        print(f"   Device ID: {device_id}")
        print(f"   Frame skip: {frame_skip}")
    
    def setup_pipeline(self, video_path):
        """Setup DALI pipeline for video processing with codec-aware configuration"""
        # Detect video codec to choose best decoding strategy
        codec_info = self._detect_video_codec(video_path)
        
        try:
            if codec_info['codec'] == 'hevc':
                print(f"üîß HEVC detected - using specialized HEVC configuration")
                self._setup_hevc_pipeline(video_path)
            else:
                print(f"üîß {codec_info['codec']} detected - using standard GPU pipeline")
                self._setup_standard_pipeline(video_path)
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è Codec-specific setup failed: {e}")
            print(f"   üîÑ Trying fallback configuration...")
            try:
                self._setup_fallback_pipeline(video_path)
            except Exception as e2:
                print(f"   ‚ùå All pipeline setups failed: {e2}")
                raise RuntimeError(f"DALI cannot handle this video file: {video_path}")
        
        print(f"‚úÖ DALI pipeline ready for: {video_path}")
    
    def _detect_video_codec(self, video_path):
        """Detect video codec and properties"""
        try:
            import subprocess
            result = subprocess.run([
                'ffprobe', '-v', 'quiet', '-print_format', 'json', 
                '-show_streams', '-select_streams', 'v:0', str(video_path)
            ], capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                import json
                data = json.loads(result.stdout)
                stream = data['streams'][0]
                return {
                    'codec': stream.get('codec_name', 'unknown'),
                    'width': stream.get('width', 0),
                    'height': stream.get('height', 0),
                    'fps': eval(stream.get('r_frame_rate', '25/1'))
                }
        except Exception as e:
            print(f"   ‚ö†Ô∏è Codec detection failed: {e}")
        
        return {'codec': 'unknown', 'width': 0, 'height': 0, 'fps': 25}
    
    def _setup_hevc_pipeline(self, video_path):
        """Setup DALI pipeline optimized for HEVC files"""
        self.pipeline = video_decode_pipeline(
            video_path=str(video_path),
            seq_length=1,  # Use sequence length 1 for HEVC to avoid timing issues
            frame_skip=self.frame_skip
        )
        
        self.iterator = DALIGenericIterator(
            [self.pipeline],
            ['images'],
            reader_name='video_reader',
            last_batch_policy=LastBatchPolicy.FILL,
            auto_reset=True
        )
    
    def _setup_standard_pipeline(self, video_path):
        """Setup standard DALI pipeline for non-HEVC files"""
        self.pipeline = video_decode_pipeline(
            video_path=str(video_path),
            seq_length=self.batch_size,
            frame_skip=self.frame_skip
        )
        
        self.iterator = DALIGenericIterator(
            [self.pipeline],
            ['images'],
            reader_name='video_reader',
            last_batch_policy=LastBatchPolicy.FILL,
            auto_reset=True
        )
    
    def _setup_fallback_pipeline(self, video_path):
        """Fallback pipeline with most conservative settings"""
        @pipeline_def(batch_size=1, num_threads=2, device_id=self.device_id)
        def minimal_pipeline():
            video = fn.readers.video(
                device="gpu",
                file_root="",
                filenames=[str(video_path)],
                sequence_length=1,  # Single frame at a time
                step=self.frame_skip * self.batch_size,  # Adjust step for larger skips
                stride=1,
                normalized=False,
                random_shuffle=False,
                pad_last_batch=True,
                skip_vfr_check=True,
                enable_frame_num=False,
                enable_timestamps=False,
                name="video_reader"
            )
            
            resized = fn.resize(video, device="gpu", size=[960, 960], interp_type=types.INTERP_LINEAR)
            normalized = fn.cast(resized, dtype=types.FLOAT) / 255.0
            transposed = fn.transpose(normalized, perm=[0, 3, 1, 2])
            
            return transposed
        
        # Temporarily adjust batch size for fallback
        self.batch_size = 1
        self.pipeline = minimal_pipeline()
        
        self.iterator = DALIGenericIterator(
            [self.pipeline],
            ['images'],
            reader_name='video_reader',
            last_batch_policy=LastBatchPolicy.FILL,
            auto_reset=True
        )
    
    def setup_pipeline_conservative(self, video_path):
        """Setup DALI pipeline with ultra-conservative settings for problematic videos"""
        try:
            print(f"üîß Setting up conservative DALI pipeline for: {video_path}")
            
            self.pipeline = self._create_conservative_pipeline(video_path)
            
            self.iterator = DALIGenericIterator(
                [self.pipeline],
                ['images'],
                reader_name='video_reader',
                last_batch_policy=LastBatchPolicy.FILL,
                auto_reset=True
            )
            
        except Exception as e:
            print(f"   ‚ùå Conservative DALI setup also failed: {e}")
            raise RuntimeError(f"DALI cannot handle this video file: {video_path}. Video may be corrupted or incompatible.")
        
        print(f"‚úÖ Conservative DALI pipeline ready for: {video_path}")
    
    def _create_conservative_pipeline(self, video_path):
        """Create a more conservative DALI pipeline for problematic videos
        Uses CPU decoding for HEVC to avoid GPU decoder issues
        """
        @pipeline_def(batch_size=self.batch_size, num_threads=4, device_id=self.device_id)
        def conservative_video_pipeline():
            # Use CPU decoding for HEVC files to avoid GPU decoder timing issues
            video = fn.readers.video(
                device="cpu",  # CPU decoding for HEVC compatibility
                file_root="",
                filenames=[str(video_path)],
                sequence_length=self.batch_size,
                step=self.frame_skip,
                stride=1,
                normalized=False,
                random_shuffle=False,
                pad_last_batch=True,
                skip_vfr_check=True,
                enable_frame_num=False,
                enable_timestamps=False,
                dont_use_mmap=True,
                name="video_reader"
            )
            
            # Transfer to GPU and resize (still GPU accelerated)
            gpu_video = video.gpu()
            resized = fn.resize(
                gpu_video,
                device="gpu", 
                size=[960, 960],
                interp_type=types.INTERP_LINEAR,
                antialias=True
            )
            
            # Normalize to float32 [0,1] and transpose to CHW (GPU operations)
            normalized = fn.cast(resized, dtype=types.FLOAT) / 255.0
            transposed = fn.transpose(normalized, perm=[0, 3, 1, 2])
            
            return transposed
        
        return conservative_video_pipeline()
    
    def get_video_info(self, video_path):
        """Get video metadata using OpenCV as fallback"""
        try:
            import cv2
            cap = cv2.VideoCapture(str(video_path))
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            cap.release()
            return total_frames, fps
        except:
            # Fallback estimation
            return 0, 30.0
    
    def __iter__(self):
        """Iterator interface for batch processing"""
        return self.iterator.__iter__()
    
    def __next__(self):
        """Get next batch of processed frames"""
        batch = next(self.iterator)
        # Extract frames tensor and convert to numpy if needed
        frames = batch[0]["frames"]
        
        # Convert PyTorch tensor to numpy for TensorRT
        if hasattr(frames, 'cpu'):
            frames = frames.cpu().numpy()
        
        return frames
    
    def cleanup(self):
        """Clean up DALI resources"""
        if self.iterator is not None:
            del self.iterator
            self.iterator = None
        
        if self.pipeline is not None:
            del self.pipeline
            self.pipeline = None

class DALIProductionBatchProcessor:
    """Production-ready batch processor with DALI GPU decoding"""
    
    def __init__(self, engine_path, batch_size=8):
        print(f"üöÄ Initializing DALI Production Batch Processor")
        print(f"   Engine: {engine_path}")
        print(f"   Batch size: {batch_size}")
        
        self.batch_size = batch_size
        # Initialize CUDA device (no longer using PyTorch)
        self.device_id = 0  # GPU 0
        
        # Load TensorRT engine
        with open(engine_path, 'rb') as f:
            runtime = trt.Runtime(TRT_LOGGER)
            self.engine = runtime.deserialize_cuda_engine(f.read())
        
        self.context = self.engine.create_execution_context()
        
        # Create CUDA stream for asynchronous execution
        self.stream = cuda.Stream()
        
        # Initialize DALI processor
        self.dali_processor = DALIVideoProcessor(
            batch_size=batch_size,
            device_id=0,
            frame_skip=25  # Default frame skip
        )
        
        # Get tensor info
        self.input_name = None
        self.output_names = []
        
        for i in range(self.engine.num_io_tensors):
            tensor_name = self.engine.get_tensor_name(i)
            is_input = self.engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT
            
            if is_input:
                self.input_name = tensor_name
            else:
                self.output_names.append(tensor_name)
        
        # Pre-allocate memory for optimal batch size
        self._allocate_memory()
        
        # Performance tracking
        self.start_time = None
        self.processed_frames = 0
        self.total_detections = 0
        self.inference_times = []
        self.decode_times = []
        
        print(f"‚úÖ Ready for GPU-accelerated processing!")
    
    def _allocate_memory(self):
        """Pre-allocate GPU memory for optimal performance"""
        # Input memory
        input_shape = (self.batch_size, 3, 960, 960)
        input_size = int(np.prod(input_shape) * 4)
        
        self.d_input = cuda.mem_alloc(input_size)
        
        # Output memory (allocate for all output tensors)
        self.output_allocations = []
        
        # Set a temporary input shape to get output shapes
        self.context.set_input_shape(self.input_name, input_shape)
        
        for output_name in self.output_names:
            try:
                output_shape = self.context.get_tensor_shape(output_name)
                
                # Convert TensorRT Dims to tuple
                if hasattr(output_shape, '__len__'):
                    shape_tuple = tuple(output_shape)
                else:
                    # Handle TensorRT Dims object
                    shape_tuple = tuple(output_shape[i] for i in range(len(output_shape)))
                
                output_size = int(np.prod(shape_tuple) * 4)
                d_output = cuda.mem_alloc(output_size)
                h_output = cuda.pagelocked_empty(shape_tuple, dtype=np.float32)
                
                self.output_allocations.append({
                    'name': output_name,
                    'device': d_output,
                    'host': h_output,
                    'shape': shape_tuple
                })
                
            except Exception as e:
                print(f"   Warning: Could not allocate for {output_name}: {e}")
        
        total_memory = (input_size + sum(np.prod(out['shape']) * 4 for out in self.output_allocations)) / (1024**2)
        print(f"   GPU memory allocated: {total_memory:.1f} MB")
    
    def process_full_video(self, video_path, output_csv, frame_skip=25, progress_interval=300):
        """Process complete video with DALI restart mechanism for HEVC files"""
        
        print(f"\nüìπ Processing Full Video with DALI GPU Decoding + Restart Recovery: {video_path}")
        print(f"   Frame skip: {frame_skip} (every {frame_skip}th frame)")
        print(f"   Output: {output_csv}")
        print(f"   Progress updates every: {progress_interval} seconds")
        
        self.start_time = time.time()
        last_progress_time = self.start_time
        
        # Get total video info once
        total_frames, fps = self._get_video_info_ffprobe(video_path)
        duration_hours = (total_frames / fps) / 3600 if fps > 0 else 0
        
        print(f"   Video info: {total_frames:,} frames, {fps:.1f} FPS, {duration_hours:.2f} hours")
        
        # Calculate total expected processed frames
        total_expected_frames = total_frames // frame_skip
        
        # Process video with restart mechanism
        all_results = []
        processed_frames_total = 0
        restart_count = 0
        max_restarts = 20  # Allow multiple restarts for long videos
        
        # Open CSV file for incremental writing
        with open(output_csv, 'w', newline='') as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow(['frame', 'class', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax'])
            
            while processed_frames_total < total_expected_frames and restart_count < max_restarts:
                try:
                    print(f"\nüöÄ DALI Session {restart_count + 1} - Starting from frame {processed_frames_total * frame_skip}")
                    
                    # Setup DALI for this chunk
                    self.dali_processor.frame_skip = frame_skip
                    start_frame = processed_frames_total * frame_skip
                    
                    # Setup pipeline for current position
                    if not self._setup_dali_from_position(video_path, start_frame):
                        print(f"   ‚ùå Failed to setup DALI from position {start_frame}")
                        break
                    
                    # Process this chunk
                    chunk_results, frames_processed = self._process_dali_chunk(
                        writer, processed_frames_total, frame_skip, 
                        total_expected_frames, progress_interval, last_progress_time
                    )
                    
                    processed_frames_total += frames_processed
                    all_results.extend(chunk_results)
                    
                    print(f"   ‚úÖ Chunk completed: {frames_processed} frames processed")
                    print(f"   üìä Total progress: {processed_frames_total}/{total_expected_frames} frames ({processed_frames_total/total_expected_frames*100:.1f}%)")
                    
                    # If we processed fewer frames than expected, DALI probably hit an error
                    if frames_processed < 50:  # Arbitrary threshold
                        print(f"   ‚ö†Ô∏è Small chunk size indicates DALI issue, will restart")
                        restart_count += 1
                    
                    # If we completed the video successfully, break
                    if processed_frames_total >= total_expected_frames:
                        print(f"   üéâ Video processing completed successfully!")
                        break
                    
                except Exception as e:
                    print(f"   ‚ùå DALI session {restart_count + 1} failed: {e}")
                    restart_count += 1
                    
                    if restart_count >= max_restarts:
                        print(f"   ‚ùå Maximum restarts ({max_restarts}) reached")
                        break
                    else:
                        print(f"   üîÑ Restarting DALI session {restart_count + 1}...")
                        continue
                
                # Cleanup DALI resources before next iteration
                try:
                    self.dali_processor.cleanup()
                except:
                    pass
                
                # Force garbage collection between chunks
                import gc
                gc.collect()
        
        self._print_final_results_with_restarts(processed_frames_total, total_expected_frames, restart_count)
        return all_results
    
    def _process_dali_batch(self, frames, indices):
        """Process DALI-decoded batch with TensorRT"""
        batch_start = time.time()
        
        # DALI outputs (batch_size, sequence_length, channels, height, width)
        # We need (batch_size, channels, height, width)
        if len(frames.shape) == 5:
            # Take first frame from sequence: (batch, seq, c, h, w) -> (batch, c, h, w)
            frames = frames[:, 0, :, :, :]
        
        actual_batch_size = frames.shape[0]
        
        # Set dynamic shape
        input_shape = (actual_batch_size, 3, 960, 960)
        self.context.set_input_shape(self.input_name, input_shape)
        
        # Copy DALI output to TensorRT input (GPU to GPU transfer)
        frames_contiguous = np.ascontiguousarray(frames)
        cuda.memcpy_htod_async(self.d_input, frames_contiguous, self.stream)
        
        # Set tensor addresses
        self.context.set_tensor_address(self.input_name, int(self.d_input))
        for output_alloc in self.output_allocations:
            self.context.set_tensor_address(output_alloc['name'], int(output_alloc['device']))
        
        # Execute inference with proper stream
        success = self.context.execute_async_v3(self.stream.handle)
        
        if not success:
            return []
        
        # Synchronize before copying results
        self.stream.synchronize()
        
        # Get main output (usually the largest - detection results)
        main_output = max(self.output_allocations, key=lambda x: np.prod(x['shape']))
        cuda.memcpy_dtoh(main_output['host'][:actual_batch_size], main_output['device'])
        
        # Track inference time
        inference_time = (time.time() - batch_start) * 1000
        self.inference_times.append(inference_time)
        
        # Process detections from native GPU NMS engine
        predictions = main_output['host'][:actual_batch_size]
        batch_detections = self._process_native_nms_output(predictions)
        
        # Convert to results
        results = []
        for i, (frame_idx, detections) in enumerate(zip(indices, batch_detections)):
            if detections is not None:
                boxes, scores, classes = detections
                for j in range(len(boxes)):
                    results.append({
                        'frame': frame_idx,
                        'class': int(classes[j]),
                        'confidence': float(scores[j]),
                        'xmin': float(boxes[j][0]),
                        'ymin': float(boxes[j][1]),
                        'xmax': float(boxes[j][2]),
                        'ymax': float(boxes[j][3])
                    })
                
                self.total_detections += len(boxes)
        
        self.processed_frames += len(frames)
        return results
    
    def _process_native_nms_output(self, predictions, conf_threshold=0.25):
        """Process output from TensorRT engine with native GPU NMS
        Output format: (batch_size, 300, 6) where each detection is [x1, y1, x2, y2, confidence, class]
        """
        batch_results = []
        
        for pred in predictions:
            try:
                if pred is None or pred.size == 0:
                    batch_results.append(None)
                    continue
                
                # pred shape should be (300, 6) from the native NMS engine
                # Filter detections by confidence threshold
                valid_detections = pred[pred[:, 4] > conf_threshold]
                
                if len(valid_detections) == 0:
                    batch_results.append(None)
                    continue
                
                # Extract coordinates, scores, and classes
                boxes = valid_detections[:, :4]  # [x1, y1, x2, y2]
                scores = valid_detections[:, 4]   # confidence
                classes = valid_detections[:, 5].astype(int)  # class IDs
                
                batch_results.append((boxes, scores, classes))
                
            except Exception as e:
                print(f"   Native NMS processing warning: {e}")
                batch_results.append(None)
        
        return batch_results
    
    def _print_dali_progress(self, frame_count, total_frames, fps, processed_batches):
        """Print progress with DALI-specific metrics"""
        elapsed = time.time() - self.start_time
        progress = (frame_count / total_frames * 100) if total_frames > 0 else 0
        
        # Calculate speeds
        frames_per_sec = frame_count / elapsed if elapsed > 0 else 0
        
        # Average times
        avg_inference = np.mean(self.inference_times) if self.inference_times else 0
        avg_decode = np.mean(self.decode_times) if self.decode_times else 0
        
        print(f"\nüìä Progress: {progress:.1f}% | Processed: {frame_count:,}/{total_frames:,} frames")
        print(f"   Speed: {frames_per_sec:.1f} frames/sec | Batches processed: {processed_batches}")
        print(f"   Avg decode time: {avg_decode:.1f}ms | Avg inference time: {avg_inference:.1f}ms")
        print(f"   Detections found: {self.total_detections:,}")
    
    def _print_dali_final_stats(self, frame_count, total_frames, fps, processed_batches):
        """Print final statistics with DALI performance metrics"""
        elapsed = time.time() - self.start_time
        
        print(f"\nüéâ DALI GPU Processing Complete!")
        print(f"   Total time: {elapsed/60:.1f} minutes")
        print(f"   Frames processed: {frame_count:,}")
        print(f"   Batches processed: {processed_batches}")
        print(f"   Average speed: {frame_count/elapsed:.1f} frames/second")
        
        if self.inference_times:
            avg_inference = np.mean(self.inference_times)
            print(f"   Average inference time: {avg_inference:.1f}ms per batch")
            print(f"   Inference throughput: {self.batch_size*1000/avg_inference:.1f} images/second")
        
        if self.decode_times:
            avg_decode = np.mean(self.decode_times)
            print(f"   Average DALI decode time: {avg_decode:.1f}ms per batch")
            print(f"   DALI decode throughput: {self.batch_size*1000/avg_decode:.1f} images/second")
        
        print(f"   Total detections: {self.total_detections:,}")
        
        # GPU utilization estimate
        if self.inference_times:
            theoretical_max_fps = 1000 / avg_inference * self.batch_size
            print(f"   Theoretical max throughput: {theoretical_max_fps:.1f} images/second")
    
    def _save_results(self, results_list, output_path):
        """Save detection results to CSV"""
        if not results_list:
            return
        
        df = pd.DataFrame(results_list)
        df.to_csv(output_path, index=False)
        print(f"   Saved {len(results_list)} detections to {output_path}")
    
    def _get_video_info_ffprobe(self, video_path):
        """Get video info using ffprobe (more reliable than DALI for problematic files)"""
        try:
            import subprocess
            result = subprocess.run([
                'ffprobe', '-v', 'quiet', '-count_frames', '-select_streams', 'v:0',
                '-show_entries', 'stream=nb_frames,r_frame_rate', '-of', 'csv=p=0',
                str(video_path)
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                for line in lines:
                    parts = line.split(',')
                    if len(parts) >= 2:
                        try:
                            frames = int(parts[0])
                            fps_str = parts[1]
                            fps = eval(fps_str) if '/' in fps_str else float(fps_str)
                            return frames, fps
                        except:
                            continue
        except Exception as e:
            print(f"   ‚ö†Ô∏è ffprobe failed: {e}")
        
        # Fallback to DALI if ffprobe fails
        return self.dali_processor.get_video_info(video_path)
    
    def _setup_dali_from_position(self, video_path, start_frame):
        """Setup DALI pipeline starting from a specific frame position"""
        try:
            # For restart mechanism, we'll use a simple approach since DALI doesn't support seeking
            # We'll process from the beginning but skip frames until we reach our position
            self.dali_processor.setup_pipeline(video_path)
            return True
            
        except Exception as e:
            print(f"   ‚ùå Failed to setup DALI from position {start_frame}: {e}")
            return False
    
    def _process_dali_chunk(self, csv_writer, processed_frames_so_far, frame_skip, 
                           total_expected, progress_interval, last_progress_time):
        """Process a chunk of video with DALI until it fails or completes"""
        chunk_results = []
        chunk_frames_processed = 0
        batches_in_chunk = 0
        skip_frames_count = processed_frames_so_far  # Frames to skip to reach our start position
        
        try:
            for batch_data in self.dali_processor:
                decode_start = time.time()
                
                # Extract frames from DALI batch
                if isinstance(batch_data, list) and len(batch_data) > 0:
                    batch_frames = batch_data[0]["images"]
                    
                    # Convert to numpy if needed
                    if hasattr(batch_frames, 'cpu'):
                        batch_frames = batch_frames.cpu().numpy()
                    elif hasattr(batch_frames, 'numpy'):
                        batch_frames = batch_frames.numpy()
                else:
                    continue
                
                # Handle shape variations
                if len(batch_frames.shape) == 5:
                    batch_frames = batch_frames[:, 0, :, :, :]
                elif len(batch_frames.shape) != 4:
                    print(f"   Warning: Unexpected batch shape: {batch_frames.shape}")
                    continue
                
                actual_batch_size = batch_frames.shape[0]
                
                # Skip frames if we haven't reached our start position yet
                if skip_frames_count > 0:
                    frames_to_skip = min(skip_frames_count, actual_batch_size)
                    skip_frames_count -= frames_to_skip
                    
                    if frames_to_skip == actual_batch_size:
                        # Skip this entire batch
                        continue
                    else:
                        # Skip some frames in this batch
                        batch_frames = batch_frames[frames_to_skip:]
                        actual_batch_size = batch_frames.shape[0]
                
                # Calculate absolute frame indices
                start_idx = (processed_frames_so_far + chunk_frames_processed) * frame_skip
                frame_indices = [start_idx + i * frame_skip for i in range(actual_batch_size)]
                
                decode_time = (time.time() - decode_start) * 1000
                self.decode_times.append(decode_time)
                
                # Process batch with TensorRT
                detections = self._process_dali_batch(batch_frames, frame_indices)
                
                # Write results immediately to CSV
                for result in detections:
                    csv_writer.writerow([
                        result['frame'],
                        result['class'],
                        result['confidence'],
                        result['xmin'],
                        result['ymin'],
                        result['xmax'],
                        result['ymax']
                    ])
                
                chunk_results.extend(detections)
                chunk_frames_processed += actual_batch_size
                batches_in_chunk += 1
                
                # Progress reporting
                current_time = time.time()
                if current_time - last_progress_time >= progress_interval:
                    total_processed = processed_frames_so_far + chunk_frames_processed
                    self._print_restart_progress(total_processed, total_expected, batches_in_chunk)
                    last_progress_time = current_time
                
                # Flush CSV periodically
                if batches_in_chunk % 10 == 0:
                    import csv
                    if hasattr(csv_writer, '_file'):
                        csv_writer._file.flush()
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è DALI chunk processing ended: {e}")
            print(f"   Processed {chunk_frames_processed} frames in this chunk")
        
        return chunk_results, chunk_frames_processed
    
    def _print_restart_progress(self, processed_frames, total_frames, batches):
        """Print progress during restart-based processing"""
        elapsed = time.time() - self.start_time
        progress = (processed_frames / total_frames * 100) if total_frames > 0 else 0
        frames_per_sec = processed_frames / elapsed if elapsed > 0 else 0
        
        avg_decode = np.mean(self.decode_times) if self.decode_times else 0
        decode_throughput = self.batch_size * 1000 / avg_decode if avg_decode > 0 else 0
        
        print(f"   üìä Progress: {processed_frames:,}/{total_frames:,} frames ({progress:.1f}%)")
        print(f"   ‚ö° Speed: {frames_per_sec:.1f} fps | Decode: {decode_throughput:.1f} img/s | Batches: {batches}")
    
    def _print_final_results_with_restarts(self, processed_frames, total_expected, restart_count):
        """Print final results including restart statistics"""
        elapsed = time.time() - self.start_time
        
        print(f"\nüéâ DALI GPU Processing Complete with Restart Recovery!")
        print(f"   Total time: {elapsed/60:.1f} minutes")
        print(f"   Frames processed: {processed_frames:,}/{total_expected:,}")
        print(f"   Completion rate: {processed_frames/total_expected*100:.1f}%")
        print(f"   DALI restarts: {restart_count}")
        print(f"   Average speed: {processed_frames/elapsed:.1f} frames/second")
        
        if self.decode_times:
            avg_decode = np.mean(self.decode_times)
            decode_throughput = self.batch_size * 1000 / avg_decode
            print(f"   Average DALI decode time: {avg_decode:.1f}ms per batch")
            print(f"   DALI decode throughput: {decode_throughput:.1f} images/second")
        
        if self.inference_times:
            avg_inference = np.mean(self.inference_times)
            inference_throughput = self.batch_size * 1000 / avg_inference
            print(f"   Average inference time: {avg_inference:.1f}ms per batch")
            print(f"   Inference throughput: {inference_throughput:.1f} images/second")
        
        print(f"   Total detections: {self.total_detections}")
        
        baseline_fps = 94.5
        improvement = (processed_frames/elapsed) / baseline_fps
        if improvement > 1.0:
            print(f"   üöÄ Performance: {improvement:.1f}x faster than baseline ({baseline_fps} fps)")
        else:
            print(f"   üìä Performance: {improvement:.1f}x of baseline ({baseline_fps} fps)")

def main():
    """Main entry point for DALI-accelerated inference"""
    parser = argparse.ArgumentParser(description='DALI GPU-Accelerated Production Batch Inference')
    parser.add_argument('video_path', type=str, help='Path to input video file')
    parser.add_argument('--output', type=str, help='Output CSV file path')
    parser.add_argument('--batch-size', type=int, default=8, help='Batch size for processing')
    parser.add_argument('--frame-skip', type=int, default=25, help='Process every Nth frame')
    parser.add_argument('--engine', type=str, 
                        default='/home/jonas/Documents/vscode/Auklab_ObjectDetection/models/best_batch16_nms.trt',
                        help='TensorRT engine path')
    
    args = parser.parse_args()
    
    # Check if DALI is available
    if not DALI_AVAILABLE:
        print("‚ùå NVIDIA DALI is not available. Please install it:")
        print("   pip install --extra-index-url https://developer.download.nvidia.com/compute/redist --upgrade nvidia-dali-cuda120")
        return
    
    # Validate inputs
    if not os.path.exists(args.video_path):
        print(f"‚ùå Video file not found: {args.video_path}")
        return
    
    if not os.path.exists(args.engine):
        print(f"‚ùå TensorRT engine not found: {args.engine}")
        return
    
    # Generate output path if not provided
    if args.output is None:
        video_name = Path(args.video_path).stem
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        args.output = f"detections_{video_name}_dali_{timestamp}.csv"
    
    print(f"üöÄ Starting DALI GPU-Accelerated Processing")
    print(f"   Video: {args.video_path}")
    print(f"   Output: {args.output}")
    print(f"   Batch size: {args.batch_size}")
    print(f"   Frame skip: {args.frame_skip}")
    print(f"   Engine: {args.engine}")
    
    try:
        # Initialize processor
        processor = DALIProductionBatchProcessor(
            engine_path=args.engine,
            batch_size=args.batch_size
        )
        
        # Process video
        results = processor.process_full_video(
            video_path=args.video_path,
            output_csv=args.output,
            frame_skip=args.frame_skip
        )
        
        print(f"‚úÖ Processing completed successfully!")
        print(f"   Results saved to: {args.output}")
        print(f"   Total detections: {len(results)}")
        
    except Exception as e:
        print(f"‚ùå Error during processing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()